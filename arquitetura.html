<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <title>MID-SUS — Arquitetura</title>
</head>
<body>

<h1>Arquitetura do MID-SUS</h1>

<h2>1. Intenção clínica</h2>
<ul>
  <li>Apoiar a leitura humana</li>
  <li>Não substituir decisão médica</li>
  <li>Reduzir ruído cognitivo</li>
</ul>

<h2>2. Objeto de leitura</h2>
<ul>
  <li>Imagens médicas</li>
  <li>Exames não invasivos</li>
  <li>Dados visuais já existentes</li>
</ul>

<h2>3. Tradução semântica</h2>
<ul>
  <li>Extração de achados relevantes</li>
  <li>Mapeamento de padrões</li>
  <li>Conversão para estrutura interpretável</li>
</ul>

<h2>4. Representação sonora</h2>
<ul>
  <li>Codificação auditiva dos achados</li>
  <li>Som como suporte, não como alerta</li>
  <li>Ausência de estética musical</li>
</ul>

<h2>5. Interpretação humana</h2>
<ul>
  <li>Escuta ativa</li>
  <li>Correlação com leitura visual</li>
  <li>Treinamento progressivo</li>
</ul>

<h2>6. Limites éticos</h2>
<ul>
  <li>Não realizar diagnóstico</li>
  <li>Não atuar fora de ambiente clínico</li>
  <li>Não substituir protocolos médicos</li>
</ul>

<h2>7. Instrumento base</h2>
<ul>
  <li>PSIU como instrumento cognitivo</li>
  <li>PSIU não é o projeto final</li>
  <li>PSIU opera abaixo do MID-SUS</li>
</ul>
<h2>Decisões em aberto</h2>
<ul>
  <li>Granularidade do mapeamento sonoro</li>
  <li>Relação entre tipos de achado e parâmetros sonoros</li>
  <li>Nível de treinamento necessário para a escuta humana</li>
  <li>Critérios para desligar o som (silêncio como dado)</li>
</ul>
<h2>Hipóteses</h2>
<ul>
  <li>O som pode antecipar padrões antes da leitura visual consciente</li>
  <li>Diferentes categorias de achados exigem famílias sonoras distintas</li>
  <li>Silêncio pode ser tão informativo quanto som</li>
</ul>

<h2>Descartado (até agora)</h2>
<ul>
  <li>Uso estético ou musical do som</li>
  <li>Alertas sonoros automáticos</li>
  <li>Qualquer forma de diagnóstico por áudio</li>
</ul>
<h2>Dependências técnicas mínimas</h2>
<ul>
  <li>Entrada padronizada de imagens médicas (formatos e metadados)</li>
  <li>Mecanismo de leitura computacional dos achados</li>
  <li>Camada de tradução semântica (achado → atributo)</li>
  <li>Mapeamento atributo → parâmetro sonoro</li>
  <li>Motor de síntese sonora controlável e auditável</li>
  <li>Interface simples para escuta humana (play / pause / silenciar)</li>
  <li>Registro de contexto e sessões (para comparação)</li>
</ul>

<p><a href="index.html">Voltar</a></p>

</body>
</html>

